{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils.data_utils as du\n",
    "from utils.evaluator import binarize_label\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\nTrain size: 2576\nTest size: 304\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/deeplearning/Abhijit/nas_drive/Abhijit/WholeBody/CT_ce/Data/Visceral\"\n",
    "label_dir = \"/home/deeplearning/Abhijit/nas_drive/Abhijit/WholeBody/CT_ce/Data/Visceral\"\n",
    "\n",
    "\n",
    "support_volume, support_labelmap, _, _ = du.load_and_preprocess(support_file_paths[0],\n",
    "                                                                orientation=orientation,\n",
    "                                                                remap_config=remap_config)\n",
    "support_volume = support_volume if len(support_volume.shape) == 4 else support_volume[:, np.newaxis, :,\n",
    "                                                                       :]\n",
    "support_volume, support_labelmap = torch.tensor(support_volume).type(torch.FloatTensor), \\\n",
    "                                   torch.tensor(support_labelmap).type(torch.LongTensor)\n",
    "\n",
    "support_volume, range_index = binarize_label(support_volume, support_labelmap, query_label)\n",
    "\n",
    "support_slice_indexes = np.round(np.linspace(0, len(support_volume) - 1, Num_support + 1)).astype(int)\n",
    "support_slice_indexes += (len(support_volume) // Num_support) // 2\n",
    "support_slice_indexes = support_slice_indexes[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_label = 7\n",
    "fold = '2'\n",
    "\n",
    "X, y = train_data.X, train_data.y\n",
    "y = (y == class_label)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "batch_size, _, _ = y.shape\n",
    "\n",
    "slice_with_class = np.sum(y.reshape(batch_size, -1), axis=1) > 10\n",
    "X = X[slice_with_class]\n",
    "y = y[slice_with_class]\n",
    "\n",
    "query_slice = np.random.randint(0, len(X))\n",
    "support_slice = np.random.randint(0, len(X))\n",
    "\n",
    "\n",
    "no_skip_model = torch.load('saved_models/sne_position_all_type_spatial_fold'+fold+'.pth.tar')\n",
    "# skip_model = torch.load('saved_models/sne_position_all_type_spatial_skipconn_baseline_fold'+fold+'.pth.tar')\n",
    "\n",
    "no_skip_model.cuda()\n",
    "no_skip_model.eval()\n",
    "# skip_model.cuda()\n",
    "# skip_model.eval()\n",
    "\n",
    "query_input = torch.tensor(X[query_slice])\n",
    "query_gt = torch.tensor(y[query_slice])\n",
    "\n",
    "support_input = torch.tensor(X[support_slice])\n",
    "support_gt = torch.tensor(y[support_slice])\n",
    "\n",
    "support_gt = support_gt.unsqueeze(0)\n",
    "\n",
    "condition_input = torch.cat((support_input, support_gt), dim=0)\n",
    "\n",
    "query_input = query_input.unsqueeze(0)\n",
    "condition_input = condition_input.unsqueeze(0)\n",
    "\n",
    "query_input = query_input.cuda()\n",
    "condition_input = condition_input.cuda()\n",
    "\n",
    "weights = no_skip_model.conditioner(condition_input)\n",
    "out = no_skip_model.segmentor(query_input, weights)\n",
    "\n",
    "_, segmentation_no_chhapa = torch.max(F.softmax(out, dim=1), dim=1)\n",
    "\n",
    "# weights = skip_model.conditioner(condition_input)\n",
    "# out = skip_model.segmentor(query_input, weights)\n",
    "\n",
    "# _, segmentation_chhapa = torch.max(F.softmax(out, dim=1), dim=1)\n",
    "\n",
    "ncols = 5\n",
    "fig, ax = plt.subplots(nrows=1, ncols=ncols, figsize=(20, 10), squeeze=False)\n",
    "\n",
    "ax[0][0].imshow(torch.squeeze(query_input), cmap='gray', vmin=0, vmax=1)\n",
    "ax[0][0].set_title(\"Query Input\", fontsize=10, color=\"blue\")\n",
    "ax[0][0].axis('off')\n",
    "ax[0][1].imshow(torch.squeeze(query_gt), cmap='gray', vmin=0, vmax=1)\n",
    "ax[0][1].set_title(\"Query GT\", fontsize=10, color=\"blue\")\n",
    "ax[0][1].axis('off')\n",
    "ax[0][2].imshow(torch.squeeze(segmentation_no_chhapa), cmap='gray', vmin=0, vmax=1)\n",
    "ax[0][2].set_title(\"No Chhapa\", fontsize=10, color=\"blue\")\n",
    "ax[0][2].axis('off')\n",
    "# ax[0][3].imshow(torch.squeeze(segmentation_chhapa), cmap='gray', vmin=0, vmax=1)\n",
    "# ax[0][3].set_title(\"Chhapa\", fontsize=10, color=\"blue\")\n",
    "# ax[0][3].axis('off')\n",
    "ax[0][3].imshow(torch.squeeze(support_input), cmap='gray', vmin=0, vmax=1)\n",
    "ax[0][3].set_title(\"Support Input\", fontsize=10, color=\"blue\")\n",
    "ax[0][3].axis('off')\n",
    "ax[0][4].imshow(torch.squeeze(support_gt), cmap='gray', vmin=0, vmax=1)\n",
    "ax[0][4].set_title(\"Support GT\", fontsize=10, color=\"blue\")\n",
    "ax[0][4].axis('off')\n",
    "\n",
    "fig.set_tight_layout(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
